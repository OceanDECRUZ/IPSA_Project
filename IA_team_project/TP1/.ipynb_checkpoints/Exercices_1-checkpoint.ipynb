{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>Introduction to Machine Learning</font>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/ipsa_logo.png\" width=\"100\" align=\"right\">\n",
    "\n",
    "\n",
    "> Year: **2021**\n",
    "\n",
    "> Version: **3.0**\n",
    "\n",
    "\n",
    "## <font color='black'>Contents</font>\n",
    "\n",
    "---\n",
    " \n",
    "1. [Set-Up](#Set-Up)\n",
    "2. [Linear regression with one variable](#LinearRegression)\n",
    " * [Gradient Descent](#GD)\n",
    "3. [Linear regression with multiple variables](#LinearRegression2)\n",
    " * [Feature Scaling](#FeatureScaling)\n",
    " * [Gradient Descent](#GD2)\n",
    " * [Normal Equation](#NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Welcome to the Intoduction to Machine Learning Course.\n",
    "\n",
    "The objective of this lab session is to code linear regression and to apply the algorithm to real data. You will predict how many times a Machine Learning article will be shared on Social Networks according to some of its characteristics.\n",
    "\n",
    "\n",
    "## <font color='black'>Set-Up</font>\n",
    "\n",
    "---\n",
    "\n",
    "First we will import the packages that we will need throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell Jupyter to display plots in this notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the numpy package with the alias np.\n",
    "import numpy as np           \n",
    "import pandas as pd\n",
    "\n",
    "# Import the pyplot package from matplotlib with the alias plt.\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pylab\n",
    "pylab.rcParams['figure.figsize'] = (4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'>Linear regression with one variable</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting on any task, it is often useful to understand the data by visualizing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= Load the data =======================\n",
    "data = pd.read_csv(\"articulos_ml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================= Check the dimensions ================\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>url</th>\n",
       "      <th>Word count</th>\n",
       "      <th># of Links</th>\n",
       "      <th># of comments</th>\n",
       "      <th># Images video</th>\n",
       "      <th>Elapsed days</th>\n",
       "      <th># Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Machine Learning and how do we use it ...</td>\n",
       "      <td>https://blog.signals.network/what-is-machine-l...</td>\n",
       "      <td>1888</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Companies Using Machine Learning in Cool Ways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1742</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Artificial Intelligence Is Revolutionizing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>962</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dbrain and the Blockchain of Artificial Intell...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1221</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nasa finds entire solar system filled with eig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2039</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  What is Machine Learning and how do we use it ...   \n",
       "1   10 Companies Using Machine Learning in Cool Ways   \n",
       "2  How Artificial Intelligence Is Revolutionizing...   \n",
       "3  Dbrain and the Blockchain of Artificial Intell...   \n",
       "4  Nasa finds entire solar system filled with eig...   \n",
       "\n",
       "                                                 url  Word count  # of Links  \\\n",
       "0  https://blog.signals.network/what-is-machine-l...        1888           1   \n",
       "1                                                NaN        1742           9   \n",
       "2                                                NaN         962           6   \n",
       "3                                                NaN        1221           3   \n",
       "4                                                NaN        2039           1   \n",
       "\n",
       "   # of comments  # Images video  Elapsed days  # Shares  \n",
       "0            2.0               2            34    200000  \n",
       "1            NaN               9             5     25000  \n",
       "2            0.0               1            10     42000  \n",
       "3            NaN               2            68    200000  \n",
       "4          104.0               4           131    200000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================= Let's visualize the first rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark that some entries (as for instance in the comments column) are empty.\n",
    "\n",
    "In our case, the column Shares will correspond to the target value, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word count</th>\n",
       "      <th># of Links</th>\n",
       "      <th># of comments</th>\n",
       "      <th># Images video</th>\n",
       "      <th>Elapsed days</th>\n",
       "      <th># Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1808.260870</td>\n",
       "      <td>9.739130</td>\n",
       "      <td>8.782946</td>\n",
       "      <td>3.670807</td>\n",
       "      <td>98.124224</td>\n",
       "      <td>27948.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1141.919385</td>\n",
       "      <td>47.271625</td>\n",
       "      <td>13.142822</td>\n",
       "      <td>3.418290</td>\n",
       "      <td>114.337535</td>\n",
       "      <td>43408.006839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>990.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1674.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>16458.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2369.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>35691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8401.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word count  # of Links  # of comments  # Images video  Elapsed days  \\\n",
       "count   161.000000  161.000000     129.000000      161.000000    161.000000   \n",
       "mean   1808.260870    9.739130       8.782946        3.670807     98.124224   \n",
       "std    1141.919385   47.271625      13.142822        3.418290    114.337535   \n",
       "min     250.000000    0.000000       0.000000        1.000000      1.000000   \n",
       "25%     990.000000    3.000000       2.000000        1.000000     31.000000   \n",
       "50%    1674.000000    5.000000       6.000000        3.000000     62.000000   \n",
       "75%    2369.000000    7.000000      12.000000        5.000000    124.000000   \n",
       "max    8401.000000  600.000000     104.000000       22.000000   1002.000000   \n",
       "\n",
       "            # Shares  \n",
       "count     161.000000  \n",
       "mean    27948.347826  \n",
       "std     43408.006839  \n",
       "min         0.000000  \n",
       "25%      2800.000000  \n",
       "50%     16458.000000  \n",
       "75%     35691.000000  \n",
       "max    350000.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================= Display some statistics from the dataset =======================\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table, we can read that the the mean number of words is 1808.\n",
    "There is an article with a minimum of 250 words and a maximum of 8401.\n",
    "\n",
    "Concerning the outputs, the minimum is 0 times shared and the maximum is shared 350000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaze the Word count vs. #Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = data['Word count'].values\n",
    "f2 = data['# Shares'].values\n",
    "    \n",
    "plt.scatter(f1, f2, c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We apply a cut to the oringal dataset\n",
    "filtered_data = data[(data['Word count'] <= 3500) & (data['# Shares'] <= 80000)]\n",
    "\n",
    "f1 = filtered_data['Word count'].values\n",
    "f2 = filtered_data['# Shares'].values\n",
    "    \n",
    "plt.scatter(f1, f2, c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX =filtered_data[[\"Word count\"]]\n",
    "X = np.array(dataX)\n",
    "y = filtered_data['# Shares'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='black'> Gradiend Descent</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will fit the linear regression parameters $\\theta$ to the dataset using gradient descent.\n",
    "\n",
    "Recall that the parameters of your model are the $\\theta_j$ values. These are the values you will adjust to minimize cost $J(\\theta)$. \n",
    "\n",
    "In the following lines, we add another dimension to our data to account for the $\\theta_0$ intercept term. We also initialize the parameters to 0 and the learning rate $\\alpha$ to 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Cost and Gradient descent ===================\n",
    "\n",
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "theta = np.zeros((2,1)); # initialize fitting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you perform gradient descent to learn minimize the cost function $J(\\theta)$, it is helpful to monitor the convergence by computing the cost. \n",
    "\n",
    "Firstly you will implement a function to calculate $J(\\theta)$ so you can check the convergence of your gradient descent.\n",
    "\n",
    "Complete the function below that computes $J(\\theta)$. \n",
    "Once you have completed the function, the next step will run computeCost once using $\\theta$ initialized to zeros, and you will see the cost printed to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    #COMPUTECOST Compute cost for linear regression\n",
    "    #   using theta as the parameter for linear regression to fit the data points in X and y\n",
    "    \n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "\n",
    "    #You need to return the following variables correctly \n",
    "    J = 0;\n",
    "\n",
    "    # ============================================================\n",
    " \n",
    "    J = 1/(2*m)*np.sum(np.power(np.dot(X,theta)-y,2))\n",
    "    \n",
    "    # ============================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0 ; 0] Cost computed =  60443036869.0\n",
      "Expected cost value (approx) 408398897.763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(X, y, theta);\n",
    "\n",
    "print('With theta = [0 ; 0] Cost computed = ' , J);\n",
    "print('Expected cost value (approx) 408398897.763\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement gradient descent. The loop structure has already been written. You only need to supply the updates to $\\theta$ within each iteration.\n",
    "\n",
    "A good way to verify that gradient descent is working is to look at the value of $J(\\theta)$ and check that it is decreasing with each step. The code calls computeCost on every iteration and prints the cost. If you have implemented gradient descent and computeCost correctly, your value of $J(\\theta)$ should never increase, and should converge to a  value by the end of the algorithm.\n",
    "\n",
    "After you have finished, you will use the final parameters to plot the linear fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0]  # number of training examples\n",
    "    \n",
    "    # make a copy of theta, to avoid changing the original array, since numpy arrays\n",
    "    # are passed by reference to functions\n",
    "    theta = theta.copy()\n",
    "\n",
    "    \n",
    "    J_history = [] # Use a python list to save cost in every iteration\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ====================================================================\n",
    "         \n",
    "        A = np.dot(X, theta)\n",
    "        theta = theta - (alpha / m) * np.dot(X.T, (A - y))\n",
    "            \n",
    "            \n",
    "        # =====================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta found by gradient descent:\n",
      "\n",
      "[ 0.02780782 11.16293235]\n",
      "Expected theta values (approx)\n",
      "\n",
      " 0.0278\n",
      "  11.162\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta = np.zeros(2); # initialize fitting parameters\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 1000;\n",
    "alpha = 1e-8;\n",
    "\n",
    "theta, J = gradientDescent(X, y, theta, alpha, iterations);\n",
    "\n",
    "print('Theta found by gradient descent:\\n');\n",
    "print(theta);\n",
    "print('Expected theta values (approx)\\n');\n",
    "print(' 0.0278\\n  11.162\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='black'> Linear regression with multiple variables</font>\n",
    "\n",
    "In this part, you will implement linear regression with multiple variables to predict the number of shares of a machine learning article. We will create a new variable that is the sum of the links, comments and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= Load the data =======================\n",
    "\n",
    "suma = (filtered_data[\"# of Links\"] + filtered_data['# of comments'].fillna(0) + filtered_data['# Images video'])\n",
    "\n",
    "dataX2 =  pd.DataFrame()\n",
    "dataX2[\"Word count\"] = filtered_data[\"Word count\"]\n",
    "dataX2[\"suma\"] = suma\n",
    "X = np.array(dataX2)\n",
    "y = filtered_data['# Shares'].values\n",
    "\n",
    "m = y.shape[0] # number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### <font color='black'> Feature Scaling</font>\n",
    "\n",
    "By looking at the values, note that the word count are about 1000 times the sum of the other variables. When features differ by orders of magnitude, performing feature scaling can make gradient descent converge much more quickly.\n",
    "\n",
    "You need to fill the cell below to perform feature scaling.\n",
    "- Subtract the mean value of each feature from the dataset.\n",
    "- After subtracting the mean, additionally scale (divide) the feature values by their respective “standard deviation\".\n",
    "\n",
    "When normalizing the features, it is important to store the values used for normalization - the mean value and the standard deviation. \n",
    "\n",
    "Given a new input x, we must first normalize x using the mean and standard deviation that we had previously computed from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    #FEATURENORMALIZE Normalizes the features in X \n",
    "    #   FEATURENORMALIZE(X) returns a normalized version of X where\n",
    "    #   the mean value of each feature is 0 and the standard deviation\n",
    "    #   is 1. This is often a good preprocessing step to do when\n",
    "    #   working with learning algorithms.\n",
    "\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    # ===========================================================\n",
    "\n",
    "    mu = np.mean(X,axis=0);\n",
    "    sigma = np.std(X,axis=0);\n",
    "    X_norm = (X_norm - mu)/sigma\n",
    "\n",
    "    # ============================================================\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, mu, sigma = featureNormalize(X);\n",
    "\n",
    "#Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='black'> Gradient Descent</font>\n",
    "\n",
    "\n",
    "Previously, you implemented gradient descent on a univariate regression problem. The only difference now is that there is one more feature in the matrix X. \n",
    "\n",
    "The hypothesis function and the batch gradient descent update rule remain unchanged.\n",
    "If your code in the previous part (single variable) already supports multiple variables, you can use it here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # You need to return the following variable correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ===============================================================\n",
    "\n",
    "\n",
    "    J = 1/(2*m)*np.sum(np.power(np.dot(X,theta)-y,2))\n",
    "    \n",
    "    \n",
    "    # ==================================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    #GRADIENTDESCENTMULTI Performs gradient descent to learn theta\n",
    "    #   theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by\n",
    "    #   taking num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # make a copy of theta, which will be updated by gradient descent\n",
    "    theta = theta.copy()\n",
    "    SP = theta.shape;\n",
    "    J_history = []\n",
    "        \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        # =============================================================\n",
    "\n",
    "        A = np.dot(X, theta)\n",
    "        theta = theta - ((alpha / m) * (np.dot(X.T, (A - y))))\n",
    "        \n",
    "        # ==============================================================\n",
    "\n",
    "        # Save the cost J in every iteration    \n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "\n",
    "                                      \n",
    "    return theta, J_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Gradient Descent ================\n",
    "\n",
    "# Choose some alpha value\n",
    "alpha = 0.1\n",
    "num_iters = 50\n",
    "\n",
    "# Init Theta and Run Gradient Descent \n",
    "theta = np.zeros((3,1))\n",
    "\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will to try out different learning rates for the dataset and find a learning rate that converges quickly. You can change the learning rate by modifying the variable above and changing the part of the code that sets the learning rate.\n",
    "\n",
    "The cell bellow plots the values of $J(\\theta)$ against the number of the iterations.\n",
    "If you picked a good value for the learning rate, the cost will decrease in every iteration. If the value of J($\\theta$) increases, adjust your learning rate and try again. You may also want to adjust the number of iterations you are running if that will help you see the overall trend in the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0,num_iters), J_history, '-b');\n",
    "plt.xlabel('Number of iterations');\n",
    "plt.ylabel('Cost J');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the changes in the convergence curves as the learning rate changes. With a small learning rate, you should find that gradient descent takes a very long time to converge to the optimal value. Conversely, with a large learning rate, gradient descent might not converge or might even diverge.\n",
    "\n",
    "Using the best learning rate that you found, run the script to run gradient descent until convergence to find the final values of $\\theta$. Next, use this value to predict the number of shares of an article with 515 words and sum 7.  Don’t forget to normalize the features when you make this prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from gradient descent: \n",
      "\n",
      "[[2.48711556e+04 4.17835414e+04 2.08917707e+04 7.66031593e+04\n",
      "  5.90938658e+04 3.48196179e+04 2.88505405e+04 3.68093103e+04\n",
      "  6.69531509e+04 5.97902581e+04 3.18350792e+03 3.68093103e+04\n",
      "  5.47165424e+04 5.45175731e+04 5.43186039e+04 2.68608481e+04\n",
      "  1.98969245e+04 2.38763094e+03 3.78041565e+03 2.58660018e+04\n",
      "  1.39278471e+04 1.39278471e+04 2.98453867e+03 5.57113886e+03\n",
      "  1.49226934e+03 8.35670829e+03 5.27268499e+03 2.48711556e+03\n",
      "  7.53098592e+02 6.36701584e+03 3.58144641e+03 2.18866169e+01\n",
      "  2.28814632e+03 2.78556943e+03 1.29330009e+03 2.48711556e+03\n",
      "  4.47680801e+03 4.19825107e+02 1.59175396e+03 7.11315051e+02\n",
      "  9.02325526e+02 2.78556943e+03 1.29330009e+03 2.98453867e+03\n",
      "  2.78556943e+03 3.28299254e+03 2.58660018e+03 2.28814632e+03\n",
      "  1.39278471e+03 1.79072320e+03 8.62531677e+02 1.49226934e+03\n",
      "  6.27747968e+02 1.19381547e+03 9.45103914e+02 1.19381547e+03\n",
      "  1.94989860e+02 1.09433085e+03 6.64557278e+02 4.21814799e+02\n",
      "  7.95876980e+00 3.65108564e+02 4.21874490e+04 1.72406851e+03\n",
      "  3.55070566e+04 1.10039941e+04 5.10545134e+04 3.05974905e+04\n",
      "  5.81238907e+04 4.78123096e+04 0.00000000e+00 4.96229297e+03\n",
      "  2.78397768e+04 4.52207351e+04 7.61902981e+04 2.41389488e+04\n",
      "  5.23388599e+03 2.54163314e+04 0.00000000e+00 5.60854508e+04\n",
      "  1.32463775e+04 2.73343949e+04 5.48856662e+04 8.66511062e+02\n",
      "  3.95620498e+04 1.63055296e+04 2.37091752e+04 1.22057683e+04\n",
      "  1.05195040e+04 2.40812477e+04 1.35159808e+04 2.10141368e+04\n",
      "  3.20818011e+04 7.95976464e+03 2.31679789e+04 5.34431392e+04\n",
      "  5.31735359e+04 5.24403342e+04 3.94764930e+04 3.88895338e+04\n",
      "  2.79710965e+04 2.57167749e+04 2.07723892e+04 1.70566385e+04\n",
      "  5.67639359e+04 1.93199137e+04 3.28100285e+03 3.09765269e+04\n",
      "  5.12644260e+03 3.43371174e+04 7.22258359e+03 0.00000000e+00\n",
      "  2.30326798e+04 3.07526865e+04 3.44903238e+04 1.26743409e+04\n",
      "  3.65178204e+04 1.17093401e+03 4.86748412e+04 1.09980250e+04\n",
      "  4.91662953e+04 2.28993704e+04 5.39186757e+04 6.55603662e+02\n",
      "  1.65552360e+04 1.97258109e+04 1.49694511e+04 1.60767150e+04\n",
      "  3.38894366e+04 1.70357468e+04 1.54320546e+04 9.03817795e+03\n",
      "  1.63731792e+04 5.54507389e+04 1.79191702e+04 3.52095976e+04\n",
      "  2.60590020e+04 5.56258318e+04 3.94754982e+03 1.81459951e+03\n",
      "  2.94275513e+03 2.22437667e+04 8.66212608e+03 3.22230692e+03\n",
      "  2.48900577e+04 4.93583006e+04 3.34865239e+04 5.92530411e+03]\n",
      " [8.01101685e-13 1.60591400e-12 8.02956998e-13 3.23224120e-12\n",
      "  1.61563180e-12 1.16558042e-12 8.02321316e-13 1.48493345e-12\n",
      "  1.96894160e-12 1.62096089e-12 1.00778511e-13 1.48493345e-12\n",
      "  1.60904279e-12 1.61030540e-12 1.60431036e-12 8.03061279e-13\n",
      "  8.06796471e-13 1.00990253e-13 1.00452359e-13 8.00681560e-13\n",
      "  4.02460776e-13 4.02460776e-13 1.00514424e-13 2.00865274e-13\n",
      "  5.02572120e-14 2.40715351e-13 2.01964588e-13 1.00849559e-13\n",
      "  2.52752284e-14 2.01557023e-13 1.01002944e-13 7.90124105e-16\n",
      "  9.56343037e-14 1.00432637e-13 5.04104844e-14 1.00849559e-13\n",
      "  1.86934951e-13 1.25978683e-14 5.03892557e-14 2.52033633e-14\n",
      "  2.53199742e-14 1.00432637e-13 5.04104844e-14 1.00514424e-13\n",
      "  1.00432637e-13 1.01140412e-13 1.00820969e-13 9.56343037e-14\n",
      "  5.02163185e-14 5.05014722e-14 2.51233907e-14 5.02572120e-14\n",
      "  2.51704795e-14 5.04951267e-14 2.51130897e-14 5.04951267e-14\n",
      "  6.30344455e-15 3.89665948e-14 2.52408390e-14 1.25659252e-14\n",
      "  1.96767429e-16 1.26587161e-14 1.60967019e-12 5.02452820e-14\n",
      "  1.32721714e-12 4.02419817e-13 1.61852691e-12 8.04740581e-13\n",
      "  1.60840051e-12 1.61455667e-12 0.00000000e+00 2.01998379e-13\n",
      "  8.10239771e-13 1.60452182e-12 3.23632874e-12 8.07103338e-13\n",
      "  2.01629254e-13 8.08989271e-13 0.00000000e+00 1.60438016e-12\n",
      "  4.04655506e-13 8.07089812e-13 1.60923113e-12 2.51942912e-14\n",
      "  1.60419542e-12 4.03928917e-13 8.04885770e-13 4.02742048e-13\n",
      "  4.04726817e-13 8.05637975e-13 4.02619189e-13 8.05184551e-13\n",
      "  8.00939408e-13 2.01173703e-13 8.06972686e-13 1.61314476e-12\n",
      "  1.60736444e-12 1.62076825e-12 1.61399867e-12 1.60978444e-12\n",
      "  8.07175727e-13 8.09111027e-13 8.04238087e-13 5.79682153e-13\n",
      "  1.61308586e-12 8.07165072e-13 1.00610501e-13 8.02323799e-13\n",
      "  2.01083323e-13 1.14920515e-12 2.01786680e-13 0.00000000e+00\n",
      "  8.04762843e-13 8.08563693e-13 1.21325116e-12 4.02752235e-13\n",
      "  1.57910671e-12 4.36412125e-14 1.60333218e-12 4.02279998e-13\n",
      "  1.60988730e-12 8.07091919e-13 1.60592543e-12 2.52290984e-14\n",
      "  4.53137936e-13 8.06434428e-13 4.03164557e-13 3.96312667e-13\n",
      "  1.04967990e-12 5.74081094e-13 4.02112036e-13 3.66730641e-13\n",
      "  4.02911767e-13 1.61468957e-12 8.07040433e-13 1.40806830e-12\n",
      "  8.01823094e-13 1.60798831e-12 1.00651105e-13 5.02065799e-14\n",
      "  1.00786816e-13 8.06764416e-13 3.29496060e-13 1.00551437e-13\n",
      "  8.10266557e-13 1.61148100e-12 1.01777199e-12 2.01531239e-13]\n",
      " [3.58188207e-13 7.15192205e-13 3.57596103e-13 1.44212527e-12\n",
      "  7.17057965e-13 6.12424942e-13 3.62554344e-13 7.09873224e-13\n",
      "  9.69209087e-13 7.16586139e-13 4.40162738e-14 7.09873224e-13\n",
      "  7.05473270e-13 7.24814443e-13 7.08894918e-13 3.57887969e-13\n",
      "  3.54476074e-13 4.46852004e-14 4.38714931e-14 3.58003360e-13\n",
      "  1.76088482e-13 1.76088482e-13 4.41458746e-14 8.90087954e-14\n",
      "  2.20729373e-14 1.17209697e-13 8.78116113e-14 4.43095093e-14\n",
      "  1.12581563e-14 8.80325477e-14 4.49300211e-14 3.53350944e-16\n",
      "  4.49596665e-14 4.45043977e-14 2.19186782e-14 4.43095093e-14\n",
      "  8.41904336e-14 5.56778753e-15 2.20081369e-14 1.10798883e-14\n",
      "  1.11909429e-14 4.45043977e-14 2.19186782e-14 4.41458746e-14\n",
      "  4.45043977e-14 4.50173997e-14 4.38373564e-14 4.49596665e-14\n",
      "  2.22521988e-14 2.24650105e-14 1.13158614e-14 2.20729373e-14\n",
      "  1.13473827e-14 2.23426002e-14 1.09678733e-14 2.23426002e-14\n",
      "  2.74335439e-15 2.14253430e-14 1.09891433e-14 5.49912847e-15\n",
      "  8.77534786e-17 5.64244397e-15 7.19649531e-13 2.20485283e-14\n",
      "  6.36151070e-13 1.80193282e-13 7.03419667e-13 3.54040887e-13\n",
      "  7.16276522e-13 7.20661397e-13 0.00000000e+00 8.96725219e-14\n",
      "  3.53696652e-13 7.15766185e-13 1.42966382e-12 3.56649998e-13\n",
      "  9.01403609e-14 3.62244650e-13 0.00000000e+00 7.10272850e-13\n",
      "  1.77464182e-13 3.56731606e-13 7.23947279e-13 1.11221252e-14\n",
      "  7.16034965e-13 1.79966209e-13 3.52704896e-13 1.78751359e-13\n",
      "  1.78033793e-13 3.52014791e-13 1.80873602e-13 3.53890489e-13\n",
      "  3.57862669e-13 8.80992192e-14 3.61863573e-13 7.16424225e-13\n",
      "  7.12298719e-13 7.23838212e-13 7.12668825e-13 7.16543573e-13\n",
      "  3.61255382e-13 3.62203792e-13 3.53637349e-13 2.74686037e-13\n",
      "  7.24069865e-13 3.56577205e-13 4.50465507e-14 3.57480774e-13\n",
      "  9.06843795e-14 5.69057415e-13 8.90304174e-14 0.00000000e+00\n",
      "  3.60569020e-13 3.61876186e-13 5.76687608e-13 1.75939679e-13\n",
      "  6.69815115e-13 2.25405927e-14 7.21681520e-13 1.75746474e-13\n",
      "  7.14366769e-13 3.58897195e-13 7.03105936e-13 1.09763035e-14\n",
      "  1.99417467e-13 3.50883792e-13 1.77342099e-13 1.80094588e-13\n",
      "  5.11378376e-13 2.79103183e-13 1.80861787e-13 1.81210677e-13\n",
      "  1.76270565e-13 7.22013951e-13 3.51861020e-13 6.56339387e-13\n",
      "  3.57363286e-13 7.19366694e-13 4.35930771e-14 2.25333165e-14\n",
      "  4.44769579e-14 3.58346434e-13 1.54114850e-13 4.50297154e-14\n",
      "  3.58764973e-13 7.16793064e-13 5.02680180e-13 9.02869371e-14]]\n"
     ]
    }
   ],
   "source": [
    "# Display gradient descent's result\n",
    "print('Theta computed from gradient descent: \\n');\n",
    "print(theta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of shares: \n",
      " None\n",
      "True number of shares: 27000\n"
     ]
    }
   ],
   "source": [
    "# Predict the value of a a new input x = [515, 7]\n",
    "\n",
    "# ===========================================================\n",
    "# Recall you need to add the column of ones and normalize the input vector\n",
    "\n",
    "shares = None\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print('Predicted number of shares: \\n', shares)\n",
    "print('True number of shares: 27000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equations\n",
    "\n",
    "\n",
    "We have seen that the closed-form solution to linear regression is\n",
    "\n",
    "$$ \\theta = \\left( X^T X\\right)^{-1} X^T {y}$$\n",
    "\n",
    "Using this formula does not require any feature scaling, and you will get an exact solution in one calculation: there is no \"loop until convergence” like in gradient descent.\n",
    "Complete the code below to use the formula to calculate $\\theta$. Remember that while you don’t need to scale your features, we still need to add a column of 1’s to the X matrix to have an intercept term ($\\theta_0$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Normal Equations ================\n",
    "\n",
    "# Load Data\n",
    "suma = (filtered_data[\"# of Links\"] + filtered_data['# of comments'].fillna(0) + filtered_data['# Images video'])\n",
    "\n",
    "dataX2 =  pd.DataFrame()\n",
    "dataX2[\"Word count\"] = filtered_data[\"Word count\"]\n",
    "dataX2[\"suma\"] = suma\n",
    "X = np.array(dataX2)\n",
    "y = filtered_data['# Shares'].values\n",
    "\n",
    "m = y.shape[0] # number of training examples\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the cell below for the function `normalEqn`. You should use the formula above to calculate $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    # ================================================================\n",
    "    XTX_inv = np.linalg.pinv(np.dot(X.transpose(),X));\n",
    "\n",
    "    C = np.dot(X.transpose(),y);\n",
    "\n",
    "    theta = np.dot(XTX_inv,C);\n",
    "    \n",
    "    # =================================================================\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from the normal equation : \n",
      "\n",
      "[ 1.69218911e+04  6.63216324e+00 -4.83407538e+02]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the parameters from the normal equation\n",
    "theta = normalEqn(X, y);\n",
    "\n",
    "#Display normal equation's result\n",
    "print('Theta computed from the normal equation : \\n');\n",
    "print(theta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of shares: (using normal equations)\n",
      " 16953.602403069577\n",
      "True number of shares: 27000\n"
     ]
    }
   ],
   "source": [
    "# Predict the value of a a new input x = [515, 7]\n",
    "\n",
    "# ============================================================\n",
    "# Recall you need to add the column of ones and normalize the input vector\n",
    "\n",
    "shares = np.dot([1, 515, 7],theta);\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print('Predicted number of shares: (using normal equations)\\n', shares)\n",
    "print('True number of shares: 27000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
